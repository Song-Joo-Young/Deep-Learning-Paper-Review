{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **라이브러리 설치**"
      ],
      "metadata": {
        "id": "2aoGxj1cpdPj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phs3yGFckPxR",
        "outputId": "2ff6392f-0090-4a8a-b1de-e1510b3cf626"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 10.3 MB of archives.\n",
            "After this operation, 34.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n",
            "Fetched 10.3 MB in 2s (4,554 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 120893 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "# 한글 출력 폰트 설치\n",
        "!apt-get install -y fonts-nanum\n",
        "!fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한글 토큰화 라이브러리 설치\n",
        "!pip3 install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm6OhcTRkXjA",
        "outputId": "f9844881-51cb-4c28-aaf8-ad936af71fdc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.3)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **데이터세트 불러오기**"
      ],
      "metadata": {
        "id": "pQMopaAmplgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 한영 번역 데이터셋 포함 저장소\n",
        "!git clone https://github.com/Song-Joo-Young/korean-parallel-corpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljGkVIwIkb6-",
        "outputId": "b6c3af34-340e-46d2-f568-650dc5ed6799"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'korean-parallel-corpora'...\n",
            "remote: Enumerating objects: 173, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 173 (delta 18), reused 0 (delta 0), pack-reused 131\u001b[K\n",
            "Receiving objects: 100% (173/173), 20.48 MiB | 10.08 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋이 저장될 폴더 생성\n",
        "!mkdir -p ./dataset\n",
        "\n",
        "# 압축 해제\n",
        "!tar -xvf ./korean-parallel-corpora/korean-english-news-v1/korean-english-park.train.tar.gz -C ./dataset\n",
        "!tar -xvf ./korean-parallel-corpora/korean-english-news-v1/korean-english-park.test.tar.gz -C ./dataset\n",
        "!tar -xvf ./korean-parallel-corpora/korean-english-news-v1/korean-english-park.dev.tar.gz -C ./dataset\n",
        "\n",
        "# 학습(training) 데이터셋 이름 변경\n",
        "!mv ./dataset/korean-english-park.train.en ./dataset/train.en\n",
        "!mv ./dataset/korean-english-park.train.ko ./dataset/train.ko\n",
        "\n",
        "# 평가(validation) 데이터셋 이름 변경\n",
        "!mv ./dataset/korean-english-park.dev.en ./dataset/dev.en\n",
        "!mv ./dataset/korean-english-park.dev.ko ./dataset/dev.ko\n",
        "\n",
        "# 테스트(test) 데이터셋 이름 변경\n",
        "!mv ./dataset/korean-english-park.test.en ./dataset/test.en\n",
        "!mv ./dataset/korean-english-park.test.ko ./dataset/test.ko"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhJIdVw_kkCp",
        "outputId": "82451219-bc48-4504-cb3d-423d20b31c0b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "korean-english-park.train.en\n",
            "korean-english-park.train.ko\n",
            "korean-english-park.test.en\n",
            "korean-english-park.test.ko\n",
            "korean-english-park.dev.en\n",
            "korean-english-park.dev.ko\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 확인 출력\n",
        "import random\n",
        "\n",
        "korean_lines_train = open(\"./dataset/train.ko\", 'r', encoding='utf-8').readlines()\n",
        "english_lines_train = open(\"./dataset/train.en\", 'r', encoding='utf-8').readlines()\n",
        "\n",
        "korean_lines_val = open(\"./dataset/dev.ko\", 'r', encoding='utf-8').readlines()\n",
        "english_lines_val = open(\"./dataset/dev.en\", 'r', encoding='utf-8').readlines()\n",
        "\n",
        "korean_lines_test = open(\"./dataset/test.ko\", 'r', encoding='utf-8').readlines()\n",
        "english_lines_test = open(\"./dataset/test.en\", 'r', encoding='utf-8').readlines()\n",
        "\n",
        "print(f\"한글 문장 학습 데이터 개수: {len(korean_lines_train)}개\")\n",
        "print(f\"영어 문장 학습 데이터 개수: {len(english_lines_train)}개\")\n",
        "\n",
        "print(f\"한글 문장 평가 데이터 개수: {len(korean_lines_val)}개\")\n",
        "print(f\"영어 문장 평가 데이터 개수: {len(english_lines_val)}개\")\n",
        "\n",
        "print(f\"한글 문장 테스트 데이터 개수: {len(korean_lines_test)}개\")\n",
        "print(f\"영어 문장 테스트 데이터 개수: {len(english_lines_test)}개\")\n",
        "\n",
        "index = random.randint(0, len(korean_lines_train))\n",
        "print(f\"{index + 1}번째 학습용 한글 문장:\", korean_lines_train[index], end='')\n",
        "print(f\"{index + 1}번째 학습용 영어 문장:\", english_lines_train[index], end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO8-dRU7kr76",
        "outputId": "394333ea-6602-446f-c88f-e4744449e267"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한글 문장 학습 데이터 개수: 94123개\n",
            "영어 문장 학습 데이터 개수: 94123개\n",
            "한글 문장 평가 데이터 개수: 1000개\n",
            "영어 문장 평가 데이터 개수: 1000개\n",
            "한글 문장 테스트 데이터 개수: 2000개\n",
            "영어 문장 테스트 데이터 개수: 2000개\n",
            "16841번째 학습용 한글 문장: 우고 차베스 베네수엘라 대통령도 콜롬비아의 FARC 지도자 사살에 항의하며 보고타 주재 베네수엘라 대사를 폐쇄했으며 콜롬비아 국경지역에 10개 대대를 투입했다.\n",
            "16841번째 학습용 영어 문장: The incident has triggered a crisis among the three countries, as Venezuela President Hugo Chavez also ordered 10 battalions of troops to the Colombian border and the closure of Venezuela's embassy in Bogota.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **단어 사전(Vocabulary) 클래스 정의**"
      ],
      "metadata": {
        "id": "oCWp3gs7p3RL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 사전(Vocabulary) 클래스 정의\n",
        "class Vocabulary(object):\n",
        "    def __init__(self):\n",
        "        self.UNK = '<unk>'\n",
        "        self.PAD = '<pad>'\n",
        "        self.SOS = '<sos>'\n",
        "        self.EOS = '<eos>'\n",
        "\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.word2count = {}\n",
        "\n",
        "    # 하나의 문장에 포함된 모든 토큰을 추가하는 함수\n",
        "    def add_tokens(self, sentence):\n",
        "        for word in sentence:\n",
        "            if word in self.word2count:\n",
        "                self.word2count[word] += 1\n",
        "            else:\n",
        "                self.word2count[word] = 1\n",
        "\n",
        "    def preprocess(self, min_count):\n",
        "        # 사용하지 않을 단어 집합\n",
        "        trim_words = set()\n",
        "        for word, count in self.word2count.items():\n",
        "            if count < min_count:\n",
        "                trim_words.add(word)\n",
        "\n",
        "        # 실제로 사용할 단어만 남기기\n",
        "        words = set(self.word2count.keys()) - trim_words\n",
        "        words = [self.UNK, self.PAD, self.SOS, self.EOS] + list(words)\n",
        "\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        for i, word in enumerate(words):\n",
        "            self.word2idx[word] = i\n",
        "            self.idx2word[i] = word\n",
        ""
      ],
      "metadata": {
        "id": "6HZ2Xa9XlFEv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **문장 토큰화**"
      ],
      "metadata": {
        "id": "Fwfw-aiop-iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 토큰화를 위해 특수문제 제거 함수를 정의하고 형태소 분석기 객체를 초기화\n",
        "import re\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "def clean_string(string):\n",
        "    string = string.strip() # 앞뒤로 존재하는 공백 제거\n",
        "    string = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\‘|\\<\\>`\\'…》]', '', string) # 특수문자 제거\n",
        "    return string.strip().lower() # 소문자로 변환하여 반환\n",
        "\n",
        "okt = Okt() # 한글 형태소 분석기"
      ],
      "metadata": {
        "id": "Bc3sjCJ8nd8o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터셋 토큰화\n",
        "tokenized_korean_lines_train = []\n",
        "tokenized_english_lines_train = []\n",
        "\n",
        "min_length = 4 # 단어의 개수가 4개 이상인 학습 문장 쌍만 사용\n",
        "max_length = 50 # 단어의 개수가 50개 이하인 학습 문장 쌍만 사용\n",
        "\n",
        "for i in range(len(korean_lines_train)):\n",
        "    korean = korean_lines_train[i]\n",
        "    korean = clean_string(korean)\n",
        "    korean_tokens = [line[0] for line in okt.pos(korean, norm=True)] # 한글 형태소 분석 결과 추출\n",
        "\n",
        "    english = english_lines_train[i]\n",
        "    english = clean_string(english)\n",
        "    english_tokens = english.split(' ')\n",
        "\n",
        "    if len(korean_tokens) < min_length or len(korean_tokens) > max_length:\n",
        "        continue\n",
        "    if len(english_tokens) < min_length or len(english_tokens) > max_length:\n",
        "        continue\n",
        "\n",
        "    tokenized_korean_lines_train.append(korean_tokens)\n",
        "    tokenized_english_lines_train.append(english_tokens)\n",
        "\n",
        "    if (i + 1) % 6000 == 0 or (i+1) == len(korean_lines_train):\n",
        "        print(f\"학습 데이터셋 토큰화: {i + 1}/{len(korean_lines_train)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky3nDqAbn4PT",
        "outputId": "5bc6a043-5767-4fda-9926-3e0f03f2316c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터셋 토큰화: 6000/94123\n",
            "학습 데이터셋 토큰화: 12000/94123\n",
            "학습 데이터셋 토큰화: 18000/94123\n",
            "학습 데이터셋 토큰화: 24000/94123\n",
            "학습 데이터셋 토큰화: 30000/94123\n",
            "학습 데이터셋 토큰화: 36000/94123\n",
            "학습 데이터셋 토큰화: 42000/94123\n",
            "학습 데이터셋 토큰화: 48000/94123\n",
            "학습 데이터셋 토큰화: 54000/94123\n",
            "학습 데이터셋 토큰화: 60000/94123\n",
            "학습 데이터셋 토큰화: 66000/94123\n",
            "학습 데이터셋 토큰화: 72000/94123\n",
            "학습 데이터셋 토큰화: 78000/94123\n",
            "학습 데이터셋 토큰화: 84000/94123\n",
            "학습 데이터셋 토큰화: 90000/94123\n",
            "학습 데이터셋 토큰화: 94123/94123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 데이터셋 토큰화\n",
        "tokenized_korean_lines_val = []\n",
        "tokenized_english_lines_val = []\n",
        "\n",
        "for i in range(len(korean_lines_val)):\n",
        "    korean = korean_lines_val[i]\n",
        "    korean = clean_string(korean)\n",
        "    korean_tokens = [line[0] for line in okt.pos(korean, norm=True)] # 한글 형태소 분석 결과 추출\n",
        "\n",
        "    english = english_lines_val[i]\n",
        "    english = clean_string(english)\n",
        "    english_tokens = english.split(' ')\n",
        "\n",
        "    tokenized_korean_lines_val.append(korean_tokens)\n",
        "    tokenized_english_lines_val.append(english_tokens)\n",
        "\n",
        "    if (i + 1) % 1000 == 0:\n",
        "        print(f\"평가 데이터셋 토큰화: {i + 1}/{len(korean_lines_val)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vl_DIPnooodz",
        "outputId": "3aea42c0-4643-42de-c203-fb9be91d1577"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평가 데이터셋 토큰화: 1000/1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터셋 토큰화\n",
        "tokenized_korean_lines_test = []\n",
        "tokenized_english_lines_test = []\n",
        "\n",
        "for i in range(len(korean_lines_test)):\n",
        "    korean = korean_lines_test[i]\n",
        "    korean = clean_string(korean)\n",
        "    korean_tokens = [line[0] for line in okt.pos(korean, norm=True)] # 한글 형태소 분석 결과 추출\n",
        "\n",
        "    english = english_lines_test[i]\n",
        "    english = clean_string(english)\n",
        "    english_tokens = english.split(' ')\n",
        "\n",
        "    tokenized_korean_lines_test.append(korean_tokens)\n",
        "    tokenized_english_lines_test.append(english_tokens)\n",
        "\n",
        "    if (i + 1) % 1000 == 0:\n",
        "        print(f\"테스트 데이터셋 토큰화: {i + 1}/{len(korean_lines_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4Ap4z5LpPeY",
        "outputId": "774cf13c-bb84-48da-8fa0-5484e81e0f6a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "테스트 데이터셋 토큰화: 1000/2000\n",
            "테스트 데이터셋 토큰화: 2000/2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **단어 사전 만들기**"
      ],
      "metadata": {
        "id": "baFFc2kSqHK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최소 2번 이상 등장한 단어만 사용\n",
        "korean_voca = Vocabulary()\n",
        "english_voca = Vocabulary()\n",
        "\n",
        "for i in range(len(tokenized_korean_lines_train)):\n",
        "    korean_tokens = tokenized_korean_lines_train[i]\n",
        "    english_tokens = tokenized_english_lines_train[i]\n",
        "\n",
        "    korean_voca.add_tokens(korean_tokens)\n",
        "    english_voca.add_tokens(english_tokens)\n",
        "\n",
        "korean_voca.preprocess(min_count=2)\n",
        "english_voca.preprocess(min_count=2)\n",
        "\n",
        "print(\"전체 한국어 단어 수:\", len(korean_voca.word2count))\n",
        "print(\"전체 영어 단어 수:\", len(english_voca.word2count))\n",
        "print(\"사용할 한국어 토큰 수:\", len(korean_voca.word2idx))\n",
        "print(\"사용할 영어 토큰 수:\", len(english_voca.word2idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faZFJJDRrd_O",
        "outputId": "304a99c2-dd3e-4bf9-84ad-3aaa8242a2f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 한국어 단어 수: 66683\n",
            "전체 영어 단어 수: 60443\n",
            "사용할 한국어 토큰 수: 40468\n",
            "사용할 영어 토큰 수: 36144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국어 단어 사전 word2idx 체크\n",
        "print(korean_voca.word2idx['<pad>']) # pad 패딩(padding): 1\n",
        "print(korean_voca.word2idx['<sos>']) # sos : 2\n",
        "print(korean_voca.word2idx['<eos>']) # eos : 3\n",
        "print(korean_voca.word2idx['컴퓨터'])\n",
        "print(korean_voca.word2idx['자동차'])\n",
        "print(korean_voca.word2idx['사랑'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gUMiRqHrka4",
        "outputId": "4764511e-d964-49d1-92e3-933a242cfd7d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "26489\n",
            "15431\n",
            "8012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 영어 단어 사전 word2idx 체크\n",
        "print(english_voca.word2idx['<pad>']) # 패딩(padding): 1\n",
        "print(english_voca.word2idx['<sos>']) # sos : 2\n",
        "print(english_voca.word2idx['<eos>']) # eos : 3\n",
        "print(english_voca.word2idx['computer'])\n",
        "print(english_voca.word2idx['car'])\n",
        "print(english_voca.word2idx['love'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0vCEDqfr6Jc",
        "outputId": "145e2026-adbf-43c0-cdea-8e9181d50d77"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "33752\n",
            "16083\n",
            "1928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unoknown token 이 1개 이상 포함된 문장은 데이터셋에서 제외하고 다시 학습 데이터셋 구성\n",
        "unknown_threshold = 1\n",
        "\n",
        "preprocessed_korean_lines_train = []\n",
        "preprocessed_english_lines_train = []\n",
        "\n",
        "for i in range(len(tokenized_korean_lines_train)):\n",
        "    korean_tokens = tokenized_korean_lines_train[i]\n",
        "    english_tokens = tokenized_english_lines_train[i]\n",
        "\n",
        "    is_used = True # 현재의 문장 쌍을 사용할지의 여부\n",
        "    for token in korean_tokens:\n",
        "        cnt = 0\n",
        "        if token not in korean_voca.word2idx:\n",
        "            cnt += 1\n",
        "        if cnt >= unknown_threshold:\n",
        "            is_used = False\n",
        "    for token in english_tokens:\n",
        "        cnt = 0\n",
        "        if token not in english_voca.word2idx:\n",
        "            cnt += 1\n",
        "        if cnt >= unknown_threshold:\n",
        "            is_used = False\n",
        "\n",
        "    if not is_used:\n",
        "        continue\n",
        "\n",
        "    preprocessed_korean_lines_train.append(korean_tokens)\n",
        "    preprocessed_english_lines_train.append(english_tokens)\n",
        "\n",
        "# 제외할 것 다 제외하고 실제로 사용하는 학습 문장 수\n",
        "print(\"사용할 한국어 학습 문장 수:\", len(preprocessed_korean_lines_train))\n",
        "print(\"사용할 영어 학습 문장 수:\", len(preprocessed_english_lines_train))\n",
        "\n",
        "# 랜덤 학습 데이터 하나씩 뽑아서 출력\n",
        "print(preprocessed_korean_lines_train[random.randint(0, len(preprocessed_korean_lines_train))])\n",
        "print(preprocessed_english_lines_train[random.randint(0, len(preprocessed_english_lines_train))])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTQUzZKasDPV",
        "outputId": "1bd72db1-cc43-46a4-9093-8f893d1822da"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용할 한국어 학습 문장 수: 60588\n",
            "사용할 영어 학습 문장 수: 60588\n",
            "['기후변화', '의', '피해자', '개도국', '여성']\n",
            "['again', 'nedrow', 'wrote', 'back', 'pointing', 'out', 'that', 'the', 'web', 'site', 'actually', 'belonged', 'to', 'the', 'company', 'that', 'made', 'the', 'drink', 'hardly', 'an', 'objective', 'source']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **커스텀 데이터셋 클래스**\n",
        "* 소스 문장(영어)와 타겟 문장(한국어)를 한 쌍으로 반환하는 데이터셋 클래스를 정의"
      ],
      "metadata": {
        "id": "s3sOx9RRuWvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, korean_lines, english_lines, max_seq_len):\n",
        "        self.korean_lines = korean_lines\n",
        "        self.english_lines = english_lines\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoder_input = self.get_encoder_input(self.english_lines[index])\n",
        "        decoder_input = self.get_decoder_input(self.korean_lines[index])\n",
        "\n",
        "        return encoder_input, decoder_input\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.korean_lines)\n",
        "\n",
        "    # 영어 문장 벡터화\n",
        "    def get_encoder_input(self, tokens):\n",
        "        tokens = copy.deepcopy(tokens)\n",
        "        tokens.insert(0, english_voca.SOS)\n",
        "        tokens.append(english_voca.EOS)\n",
        "        tokens = self.padding(tokens, english_voca) # 문장 뒤쪽에 패딩 붙이기\n",
        "        index_list = self.word2idx(tokens, english_voca)\n",
        "\n",
        "        return torch.tensor(index_list).to(device)\n",
        "\n",
        "    # 한글 문장 벡터화\n",
        "    def get_decoder_input(self, tokens):\n",
        "        tokens = copy.deepcopy(tokens)\n",
        "        tokens.insert(0, korean_voca.SOS)\n",
        "        tokens.append(korean_voca.EOS)\n",
        "        tokens = self.padding(tokens, korean_voca) # 문장 뒤쪽에 패딩 붙이기\n",
        "        index_list = self.word2idx(tokens, korean_voca)\n",
        "\n",
        "        return torch.tensor(index_list).to(device)\n",
        "\n",
        "    # max_seq_len보다 길이가 짧은 문장에 대해  토큰 채우기\n",
        "    def padding(self, tokens, voca):\n",
        "        if len(tokens) < self.max_seq_len:\n",
        "            tokens += [voca.PAD] * (self.max_seq_len - len(tokens))\n",
        "        else:\n",
        "            tokens = tokens[:self.max_seq_len]\n",
        "        return tokens\n",
        "\n",
        "    def word2idx(self, tokens, voca):\n",
        "        idx_list = []\n",
        "        for token in tokens:\n",
        "            try:\n",
        "                idx_list.append(voca.word2idx[token])\n",
        "            except KeyError:\n",
        "                idx_list.append(voca.word2idx[voca.UNK])\n",
        "        return idx_list"
      ],
      "metadata": {
        "id": "VTwKmpaTsoMA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 객체 초기화\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_dataset = CustomDataset(preprocessed_korean_lines_train, preprocessed_english_lines_train, max_seq_len=80)\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=128, num_workers=0)\n",
        "\n",
        "val_dataset = CustomDataset(tokenized_korean_lines_val, tokenized_english_lines_val, max_seq_len=80)\n",
        "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=128, num_workers=0)\n",
        "\n",
        "test_dataset = CustomDataset(tokenized_korean_lines_test, tokenized_english_lines_test, max_seq_len=80)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=128, num_workers=0)"
      ],
      "metadata": {
        "id": "Iti_XKqCsqfC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하나의 배치에 포함되어 있는 문장을 출력\n",
        "for i, batch in enumerate(train_loader):\n",
        "    src = batch[0]\n",
        "    trg = batch[1]\n",
        "\n",
        "    print(f\"첫 번째 배치 크기: {src.shape}\")\n",
        "\n",
        "    # 현재 배치에 있는 하나의 문장에 포함된 정보 출력\n",
        "    for i in range(src.shape[1]):\n",
        "        print(f\"인덱스 {i}: {src[0][i].item()}\") # 여기에서는 [Seq_num, Seq_len]\n",
        "\n",
        "    # 첫 번째 배치만 확인\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUY-XxUdsv0P",
        "outputId": "a948450e-6298-4c19-a040-688ec4838f9a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫 번째 배치 크기: torch.Size([128, 80])\n",
            "인덱스 0: 2\n",
            "인덱스 1: 17178\n",
            "인덱스 2: 22893\n",
            "인덱스 3: 17042\n",
            "인덱스 4: 33143\n",
            "인덱스 5: 33422\n",
            "인덱스 6: 16789\n",
            "인덱스 7: 20753\n",
            "인덱스 8: 18404\n",
            "인덱스 9: 19444\n",
            "인덱스 10: 31283\n",
            "인덱스 11: 22982\n",
            "인덱스 12: 8773\n",
            "인덱스 13: 3273\n",
            "인덱스 14: 30981\n",
            "인덱스 15: 35034\n",
            "인덱스 16: 3\n",
            "인덱스 17: 1\n",
            "인덱스 18: 1\n",
            "인덱스 19: 1\n",
            "인덱스 20: 1\n",
            "인덱스 21: 1\n",
            "인덱스 22: 1\n",
            "인덱스 23: 1\n",
            "인덱스 24: 1\n",
            "인덱스 25: 1\n",
            "인덱스 26: 1\n",
            "인덱스 27: 1\n",
            "인덱스 28: 1\n",
            "인덱스 29: 1\n",
            "인덱스 30: 1\n",
            "인덱스 31: 1\n",
            "인덱스 32: 1\n",
            "인덱스 33: 1\n",
            "인덱스 34: 1\n",
            "인덱스 35: 1\n",
            "인덱스 36: 1\n",
            "인덱스 37: 1\n",
            "인덱스 38: 1\n",
            "인덱스 39: 1\n",
            "인덱스 40: 1\n",
            "인덱스 41: 1\n",
            "인덱스 42: 1\n",
            "인덱스 43: 1\n",
            "인덱스 44: 1\n",
            "인덱스 45: 1\n",
            "인덱스 46: 1\n",
            "인덱스 47: 1\n",
            "인덱스 48: 1\n",
            "인덱스 49: 1\n",
            "인덱스 50: 1\n",
            "인덱스 51: 1\n",
            "인덱스 52: 1\n",
            "인덱스 53: 1\n",
            "인덱스 54: 1\n",
            "인덱스 55: 1\n",
            "인덱스 56: 1\n",
            "인덱스 57: 1\n",
            "인덱스 58: 1\n",
            "인덱스 59: 1\n",
            "인덱스 60: 1\n",
            "인덱스 61: 1\n",
            "인덱스 62: 1\n",
            "인덱스 63: 1\n",
            "인덱스 64: 1\n",
            "인덱스 65: 1\n",
            "인덱스 66: 1\n",
            "인덱스 67: 1\n",
            "인덱스 68: 1\n",
            "인덱스 69: 1\n",
            "인덱스 70: 1\n",
            "인덱스 71: 1\n",
            "인덱스 72: 1\n",
            "인덱스 73: 1\n",
            "인덱스 74: 1\n",
            "인덱스 75: 1\n",
            "인덱스 76: 1\n",
            "인덱스 77: 1\n",
            "인덱스 78: 1\n",
            "인덱스 79: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Multi Head Attention 아키텍처**\n",
        "* 어텐션(attention)은 **세 가지 요소**를 입력으로 받는다\n",
        "  * **쿼리(queries)**\n",
        "  * **키(keys)**\n",
        "  * **값(values)**\n",
        "  * 현재 구현에서는 Query, Key, Value의 차원이 모두 같다. (논문 내용과 동일)\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "  * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "  * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "  * **dropout_ratio**: 드롭아웃(dropout) 비율"
      ],
      "metadata": {
        "id": "aeCKORtdszk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        assert hidden_dim % n_heads == 0\n",
        "\n",
        "        self.hidden_dim = hidden_dim # 임베딩 차원\n",
        "        self.n_heads = n_heads # 헤드(head)의 개수: 서로 다른 어텐션(attention) 컨셉의 수\n",
        "        self.head_dim = hidden_dim // n_heads # 각 헤드(head)에서의 임베딩 차원\n",
        "\n",
        "        self.fc_q = nn.Linear(hidden_dim, hidden_dim) # Query 값에 적용될 FC 레이어\n",
        "        self.fc_k = nn.Linear(hidden_dim, hidden_dim) # Key 값에 적용될 FC 레이어\n",
        "        self.fc_v = nn.Linear(hidden_dim, hidden_dim) # Value 값에 적용될 FC 레이어\n",
        "\n",
        "        self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # query: [batch_size, query_len, hidden_dim]\n",
        "        # key: [batch_size, key_len, hidden_dim]\n",
        "        # value: [batch_size, value_len, hidden_dim]\n",
        "\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "\n",
        "        # Q: [batch_size, query_len, hidden_dim]\n",
        "        # K: [batch_size, key_len, hidden_dim]\n",
        "        # V: [batch_size, value_len, hidden_dim]\n",
        "\n",
        "        # hidden_dim → n_heads X head_dim 형태로 변형\n",
        "        # n_heads(h)개의 서로 다른 어텐션(attention) 컨셉을 학습하도록 유도\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        # Q: [batch_size, n_heads, query_len, head_dim]\n",
        "        # K: [batch_size, n_heads, key_len, head_dim]\n",
        "        # V: [batch_size, n_heads, value_len, head_dim]\n",
        "\n",
        "        # Attention Energy 계산\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "\n",
        "        # energy: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "        # 마스크(mask)를 사용하는 경우\n",
        "        if mask is not None:\n",
        "            # 마스크(mask) 값이 0인 부분을 -1e10으로 채우기\n",
        "            energy = energy.masked_fill(mask==0, -1e10)\n",
        "\n",
        "        # 어텐션(attention) 스코어 계산: 각 단어에 대한 확률 값\n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "\n",
        "        # attention: [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "        # 여기에서 Scaled Dot-Product Attention을 계산\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "\n",
        "        # x: [batch_size, n_heads, query_len, head_dim]\n",
        "\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        # x: [batch_size, query_len, n_heads, head_dim]\n",
        "\n",
        "        x = x.view(batch_size, -1, self.hidden_dim)\n",
        "\n",
        "        # x: [batch_size, query_len, hidden_dim]\n",
        "\n",
        "        x = self.fc_o(x)\n",
        "\n",
        "        # x: [batch_size, query_len, hidden_dim]\n",
        "\n",
        "        return x, attention"
      ],
      "metadata": {
        "id": "47LExjeXtVDX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Position-wise Feedforward 아키텍처**\n",
        "* 입력과 출력의 차원이 동일\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "  * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "  * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "  * **dropout_ratio**: 드롭아웃(dropout) 비율"
      ],
      "metadata": {
        "id": "iLk-4caYt8VW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "\n",
        "        # x: [batch_size, seq_len, pf_dim]\n",
        "\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "JKAeB9int6lx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **인코더(Encoder) 레이어 아키텍처**\n",
        "* 하나의 인코더 레이어에 대해 정의\n",
        "* 입력과 출력의 차원이 같다.\n",
        "  * 이러한 특징을 이용해 트랜스포머의 인코더는 인코더 레이어를 여러 번 중첩해 사용함\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "  * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "  * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "  * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "  * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "* <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
        "\n",
        "\n",
        "![1.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "SMRDJ1HZDJjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 하나의 임베딩이 복제되어 Query, Key, Value로 입력되는 방식\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        # self attention\n",
        "        # 필요한 경우 마스크(mask) 행렬을 이용하여 어텐션(attention)할 단어를 조절 가능\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # position-wise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        return src"
      ],
      "metadata": {
        "id": "YXqKpz3xt9sB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **인코더(Encoder) 아키텍처**\n",
        "* 전체 인코더 아키텍처를 정의\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "  * **input_dim**: 하나의 단어에 대한 원 핫 인코딩 차원\n",
        "  * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "  * **n_layers**: 내부적으로 사용할 인코더 레이어의 개수\n",
        "  * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "  * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "  * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "  * **max_length**: 문장 내 최대 단어 개수\n",
        "* 원본 논문과는 다르게 위치 임베딩(positional embedding)을 학습하는 형태로 구현\n",
        "  * BERT와 같은 모던 트랜스포머 아키텍처에서 사용되는 방식\n",
        "* <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정"
      ],
      "metadata": {
        "id": "NAiL303Tt-IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        # pos: [batch_size, src_len]\n",
        "\n",
        "        # 소스 문장의 임베딩과 위치 임베딩을 더한 것을 사용\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # 모든 인코더 레이어를 차례대로 거치면서 순전파(forward) 수행\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        return src # 마지막 레이어의 출력을 반환"
      ],
      "metadata": {
        "id": "0viTEThjufM2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **디코더(Decoder) 레이어 아키텍처**\n",
        "* 하나의 디코더 레이어에 대해 정의\n",
        "* 입력과 출력의 차원이 같다.\n",
        "  * 이러한 특징을 이용해 트랜스포머의 디코더는 디코더 레이어를 여러 번 중첩해 사용\n",
        "* 디코더 레이어에서는 두 개의 Multi-Head Attention 레이어가 사용된다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "  * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "  * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "  * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "  * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "* 소스 문장의 <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
        "* 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용"
      ],
      "metadata": {
        "id": "D4AAtxSyugVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 인코더의 출력 값(enc_src)을 어텐션(attention)하는 구조\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "        # trg_mask: [batch_size, trg_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        # self attention\n",
        "        # 자기 자신에 대하여 어텐션(attention)\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        # encoder attention\n",
        "        # 디코더의 쿼리(Query)를 이용해 인코더를 어텐션(attention)\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        # positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        return trg, attention"
      ],
      "metadata": {
        "id": "dl-2AHPbuf1I"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **디코더(Decoder) 아키텍처**\n",
        "* 전체 디코더 아키텍처를 정의\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "  * **output_dim**: 하나의 단어에 대한 원 핫 인코딩 차원\n",
        "  * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "  * **n_layers**: 내부적으로 사용할 인코더 레이어의 개수\n",
        "  * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "  * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "  * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "  * **max_length** : 문장 내 최대 단어 개수\n",
        "* 원본 논문과는 다르게 위치 임베딩(positional embedding)을 학습하는 형태로 구현\n",
        "  * BERT와 같은 모던 트랜스포머 아키텍처에서 사용되는 방식\n",
        "* <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
        "* Seq2Seq과는 마찬가지로 실제로 추론(inference) 시기에서는 디코더를 반복적으로 넣어야 한다.\n",
        "  * 학습(training) 시기에서는 한 번에 출력 문장을 구해 학습할 수 있다.\n",
        "* 소스 문장의 <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
        "* 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용"
      ],
      "metadata": {
        "id": "EBRwzSX_uiwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        # trg: [batch_size, trg_len]\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "        # trg_mask: [batch_size, trg_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        # pos: [batch_size, trg_len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            # 소스 마스크와 타겟 마스크 모두 사용\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "\n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "w1rZKzMPuiL4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **트랜스포머(Transformer) 아키텍처**\n",
        "* 최종적인 전체 트랜스포머(Transformer) 모델을 정의\n",
        "* 입력이 들어왔을 때 앞서 정의한 인코더와 디코더를 거쳐 출력 문장을 생성"
      ],
      "metadata": {
        "id": "7U9MjwRrunC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    # 소스 문장의  토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # src_mask: [batch_size, 1, 1, src_len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    # 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        # trg: [batch_size, trg_len]\n",
        "\n",
        "        \"\"\" (마스크 예시)\n",
        "        1 0 0 0 0\n",
        "        1 1 0 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 0 0\n",
        "        \"\"\"\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # trg_pad_mask: [batch_size, 1, 1, trg_len]\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        \"\"\" (마스크 예시)\n",
        "        1 0 0 0 0\n",
        "        1 1 0 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 1 0\n",
        "        1 1 1 1 1\n",
        "        \"\"\"\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "\n",
        "        # trg_sub_mask: [trg_len, trg_len]\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "        # trg: [batch_size, trg_len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        # src_mask: [batch_size, 1, 1, src_len]\n",
        "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        return output, attention"
      ],
      "metadata": {
        "id": "664YZrXuukiU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **학습(Training)**"
      ],
      "metadata": {
        "id": "L-nPUSFZumj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 파라미터 설정 및 모델 초기화\n",
        "INPUT_DIM = len(english_voca.word2idx)\n",
        "OUTPUT_DIM = len(korean_voca.word2idx)\n",
        "HIDDEN_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1"
      ],
      "metadata": {
        "id": "PneSp8ncuorh"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_PAD_IDX = english_voca.word2idx[english_voca.PAD]\n",
        "TRG_PAD_IDX = korean_voca.word2idx[korean_voca.PAD]\n",
        "\n",
        "# 인코더(encoder)와 디코더(decoder) 객체 선언\n",
        "enc = Encoder(INPUT_DIM, HIDDEN_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
        "dec = Decoder(OUTPUT_DIM, HIDDEN_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
        "\n",
        "# Transformer 객체 선언\n",
        "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "metadata": {
        "id": "6z9-zvT7uuBY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 파라미터 체크 및 가중치 초기화\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZpnwEXTuwzC",
        "outputId": "5aef3bcd-6d0a-4f9a-8ef7-12ca10dc2c52"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 34,017,812 trainable parameters\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(36144, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(40468, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=40468, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Adam optimizer로 학습 최적화\n",
        "LEARNING_RATE = 0.0005\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "metadata": {
        "id": "CY2mQdF9u_uW"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습(train) 함수\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train() # 학습 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # 전체 학습 데이터를 확인하며\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch[0]\n",
        "        trg = batch[1]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 출력 단어의 마지막 인덱스()는 제외\n",
        "        # 입력을 할 때는 부터 시작하도록 처리\n",
        "        output, _ = model(src, trg[:,:-1]) # output에 마지막이 가 나오도록\n",
        "\n",
        "        # output: [배치 크기, trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기, trg_len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        # 출력 단어의 인덱스 0()은 제외\n",
        "        trg = trg[:,1:].contiguous().view(-1) # 가 붙어 있는 상황\n",
        "\n",
        "        # output: [배치 크기 * trg_len - 1, output_dim]\n",
        "        # trg: [배치 크기 * trg len - 1]\n",
        "\n",
        "        # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward() # 기울기(gradient) 계산\n",
        "\n",
        "        # 기울기(gradient) clipping 진행\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 전체 손실 값 계산\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "DoELgR4PvT8s"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가(evaluate) 함수\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval() # 평가 모드\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # 전체 평가 데이터를 확인하며\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch[0]\n",
        "            trg = batch[1]\n",
        "\n",
        "            # 출력 단어의 마지막 인덱스()는 제외\n",
        "            # 입력을 할 때는 부터 시작하도록 처리\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "\n",
        "            # output: [배치 크기, trg_len - 1, output_dim]\n",
        "            # trg: [배치 크기, trg_len]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            # 출력 단어의 인덱스 0()은 제외\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "\n",
        "            # output: [배치 크기 * trg_len - 1, output_dim]\n",
        "            # trg: [배치 크기 * trg len - 1]\n",
        "\n",
        "            # 모델의 출력 결과와 타겟 문장을 비교하여 손실 계산\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            # 전체 손실 값 계산\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "metadata": {
        "id": "vJPBOW-dvVSg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "IqF4-zvDvW1j"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "import random\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time() # 시작 시간 기록\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, val_loader, criterion)\n",
        "\n",
        "    end_time = time.time() # 종료 시간 기록\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'transformer_english_to_korean.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
        "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI9SXZRovYkQ",
        "outputId": "9a8b25ec-299a-43d2-aa57-d76a63ef23ae"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 3m 1s\n",
            "\tTrain Loss: 6.069 | Train PPL: 432.073\n",
            "\tValidation Loss: 5.554 | Validation PPL: 258.289\n",
            "Epoch: 02 | Time: 3m 0s\n",
            "\tTrain Loss: 4.565 | Train PPL: 96.062\n",
            "\tValidation Loss: 5.233 | Validation PPL: 187.432\n",
            "Epoch: 03 | Time: 3m 0s\n",
            "\tTrain Loss: 3.857 | Train PPL: 47.335\n",
            "\tValidation Loss: 5.128 | Validation PPL: 168.623\n",
            "Epoch: 04 | Time: 3m 0s\n",
            "\tTrain Loss: 3.292 | Train PPL: 26.889\n",
            "\tValidation Loss: 5.175 | Validation PPL: 176.832\n",
            "Epoch: 05 | Time: 3m 0s\n",
            "\tTrain Loss: 2.815 | Train PPL: 16.701\n",
            "\tValidation Loss: 5.306 | Validation PPL: 201.442\n",
            "Epoch: 06 | Time: 3m 0s\n",
            "\tTrain Loss: 2.415 | Train PPL: 11.191\n",
            "\tValidation Loss: 5.488 | Validation PPL: 241.893\n",
            "Epoch: 07 | Time: 3m 0s\n",
            "\tTrain Loss: 2.088 | Train PPL: 8.067\n",
            "\tValidation Loss: 5.684 | Validation PPL: 294.123\n",
            "Epoch: 08 | Time: 3m 0s\n",
            "\tTrain Loss: 1.819 | Train PPL: 6.164\n",
            "\tValidation Loss: 5.908 | Validation PPL: 367.810\n",
            "Epoch: 09 | Time: 3m 0s\n",
            "\tTrain Loss: 1.603 | Train PPL: 4.970\n",
            "\tValidation Loss: 6.130 | Validation PPL: 459.647\n",
            "Epoch: 10 | Time: 3m 0s\n",
            "\tTrain Loss: 1.429 | Train PPL: 4.174\n",
            "\tValidation Loss: 6.357 | Validation PPL: 576.452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 번역(translation) 함수\n",
        "def translate_sentence(english, model, device, max_len=80, logging=True):\n",
        "    model.eval() # 평가 모드\n",
        "\n",
        "    english = clean_string(english)\n",
        "    tokens = english.split(' ')\n",
        "\n",
        "    # 처음에  토큰, 마지막에  토큰 붙이기\n",
        "    tokens = [english_voca.SOS] + tokens + [english_voca.EOS]\n",
        "    if logging:\n",
        "        print(f\"전체 소스 토큰: {tokens}\")\n",
        "\n",
        "    src_indexes = []\n",
        "    for token in tokens:\n",
        "        try:\n",
        "            src_indexes.append(english_voca.word2idx[token])\n",
        "        except KeyError:\n",
        "            src_indexes.append(english_voca.word2idx[english_voca.UNK])\n",
        "    if logging:\n",
        "        print(f\"소스 문장 인덱스: {src_indexes}\")\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    # 소스 문장에 따른 마스크 생성\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    # 인코더(endocer)에 소스 문장을 넣어 문맥 벡터(context vector) 계산\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    # 처음에는  토큰 하나만 가지고 있도록 하기\n",
        "    trg_indexes = [korean_voca.word2idx[korean_voca.SOS]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        # 출력 문장에 따른 마스크 생성\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # 출력 문장에서 가장 마지막 단어만 사용\n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        trg_indexes.append(pred_token) # 출력 문장에 더하기\n",
        "\n",
        "        # 를 만나는 순간 끝\n",
        "        if pred_token == korean_voca.word2idx[korean_voca.EOS]:\n",
        "            break\n",
        "\n",
        "    # 각 출력 단어 인덱스를 실제 단어로 변환\n",
        "    trg_tokens = [korean_voca.idx2word[i] for i in trg_indexes]\n",
        "\n",
        "    # 첫 번째 는 제외하고 출력 문장 반환\n",
        "    return trg_tokens[1:], attention"
      ],
      "metadata": {
        "id": "p11_YuLuvfj1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 번역 결과 확인. 성능은 그닥 좋지 않은 모습..\n",
        "for _ in range(3):\n",
        "\n",
        "    example_idx = random.randint(0, len(korean_lines_test))\n",
        "\n",
        "    src = english_lines_test[example_idx]\n",
        "    trg = korean_lines_test[example_idx]\n",
        "\n",
        "    print(f'소스 문장: {src}', end='')\n",
        "    print(f'타겟 문장: {trg}', end='')\n",
        "\n",
        "    translation, attention = translate_sentence(src, model, device, logging=True)\n",
        "\n",
        "    print(\"모델 출력 결과:\", \" \".join(translation))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5RjYjg-vgJM",
        "outputId": "374571c5-c9b8-499c-efe8-0f7fbfb51974"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소스 문장: (CNN) Virgin Media stepped up its campaign to combat music piracy Thursday, when it issued letters to around 800 customers warning them against downloading illegal music files via file-sharing sites.\n",
            "타겟 문장: 영국 음반사인 버진 미디어가 3일(현지시간) 불법 음원 다운로드와 관련해 이용자 800명에게 경고문을 발송하며 저작권 침해 금지운동을 더욱 강화하고 있다.\n",
            "전체 소스 토큰: ['<sos>', '(cnn)', 'virgin', 'media', 'stepped', 'up', 'its', 'campaign', 'to', 'combat', 'music', 'piracy', 'thursday', 'when', 'it', 'issued', 'letters', 'to', 'around', '800', 'customers', 'warning', 'them', 'against', 'downloading', 'illegal', 'music', 'files', 'via', 'filesharing', 'sites', '<eos>']\n",
            "소스 문장 인덱스: [2, 23460, 34046, 7352, 6533, 3267, 2729, 21686, 30376, 35800, 14336, 19167, 16910, 17443, 11163, 339, 30584, 30376, 35517, 8850, 5759, 27001, 11649, 33846, 0, 21012, 14336, 19501, 32278, 13875, 3090, 3]\n",
            "모델 출력 결과: 이 같은 노래 의 웹사이트 에 의하면 이 달 초 호화 요트 개인 적 인 정보 를 보호 하기 위해 이 들 에게 불법 적 인 재원 을 마련 해 전세계 적 으로 전달 했다 <eos>\n",
            "\n",
            "소스 문장: WASHINGTON (CNN) &#8212; The fight for Hispanic voters takes center stage Tuesday as John McCain and Barack Obama both speak separately in Washington to the League of United Latin American Citizens.\n",
            "타겟 문장: 미국 공화당의 대선후보인 존 매케인 상원의원과 민주당의 대선후보인 버락 오바마 상원의원이 8일(현지시간) 워싱턴에서 열린 ‘라틴계 미국인 시민연합(League of United Latin American Citizens)’회의에 참석, 히스패닉 표심 잡기 경쟁을 벌였다.\n",
            "전체 소스 토큰: ['<sos>', 'washington', '(cnn)', '8212;', 'the', 'fight', 'for', 'hispanic', 'voters', 'takes', 'center', 'stage', 'tuesday', 'as', 'john', 'mccain', 'and', 'barack', 'obama', 'both', 'speak', 'separately', 'in', 'washington', 'to', 'the', 'league', 'of', 'united', 'latin', 'american', 'citizens', '<eos>']\n",
            "소스 문장 인덱스: [2, 12397, 23460, 27939, 32062, 9347, 16811, 35304, 16768, 26540, 38, 7332, 18499, 3565, 351, 26101, 17220, 5736, 16744, 9637, 29430, 24938, 22982, 12397, 30376, 32062, 17015, 3273, 6364, 31902, 27558, 18183, 3]\n",
            "모델 출력 결과: 미국 민주당 대선 후보 인 버락 오바마 상원의원 이 4일 ( 현지 시간 ) 미국 버지니아주 워싱턴 dc 메릴랜드 애 코스 켄키 아프 디포 ( 심장 ) 을 이용 해 탈락 했다 <eos>\n",
            "\n",
            "소스 문장: 23-year-old Private Geronimo Ramirez, began serving his prison term early last month, when he was convicted of beating and raping the 66-year-old Korean woman in a residential area of western Seoul.\n",
            "타겟 문장: 23세의 제로니모 라미레즈 이병은 서울 서쪽의 주거지역에서 66세의 한국여성을 폭행하고 강간한 것에 대해 유죄판결을 받은 지난 달 초부터 복역을 시작했다…\n",
            "전체 소스 토큰: ['<sos>', '23yearold', 'private', 'geronimo', 'ramirez', 'began', 'serving', 'his', 'prison', 'term', 'early', 'last', 'month', 'when', 'he', 'was', 'convicted', 'of', 'beating', 'and', 'raping', 'the', '66yearold', 'korean', 'woman', 'in', 'a', 'residential', 'area', 'of', 'western', 'seoul', '<eos>']\n",
            "소스 문장 인덱스: [2, 12836, 20944, 0, 25316, 5653, 22562, 4785, 21875, 24581, 15736, 30747, 28773, 17443, 26477, 27735, 18251, 3273, 19927, 17220, 24429, 32062, 16320, 23960, 4159, 22982, 17042, 4256, 25060, 3273, 2063, 3596, 3]\n",
            "모델 출력 결과: 캐나다 출신 의 교도관 은 지난해 12월 31일 부터 2007년 까지 여성 복무 했으며 19 명 은 복무 중이 다 <eos>\n",
            "\n"
          ]
        }
      ]
    }
  ]
}